{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  Ãœbersprungen (ungÃ¼ltiger Ordnername): \"\n",
      "âœ… Kombinierter Datensatz wurde unter '/Users/MeinNotebook/DocDig/Scans_for_Dataset/CombinedDataset' erstellt.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Ordnerpfade definieren\n",
    "google_drive_dir = '/Users/MeinNotebook/DocDig/Scans_for_Dataset/Vogelarten'\n",
    "additional_data_dir = '/Users/MeinNotebook/DocDig/Scans_for_Dataset/Dataset'\n",
    "combined_dir = '/Users/MeinNotebook/DocDig/Scans_for_Dataset/CombinedDataset'\n",
    "\n",
    "# Zielordner neu erstellen\n",
    "os.makedirs(combined_dir, exist_ok=True)\n",
    "\n",
    "# Alle Klassen aus dem Google-Drive-Ordner Ã¼bernehmen\n",
    "for class_name in os.listdir(google_drive_dir):\n",
    "    # Ãœberspringe Ordner mit AnfÃ¼hrungszeichen im Namen\n",
    "    if '\"' in class_name or \"'\" in class_name:\n",
    "        print(f\"âš ï¸  Ãœbersprungen (ungÃ¼ltiger Ordnername): {class_name}\")\n",
    "        continue\n",
    "\n",
    "    src_gd_class = os.path.join(google_drive_dir, class_name)\n",
    "    src_additional_class = os.path.join(additional_data_dir, class_name)\n",
    "    dst_class = os.path.join(combined_dir, class_name)\n",
    "\n",
    "    if not os.path.isdir(src_gd_class):\n",
    "        continue\n",
    "\n",
    "    os.makedirs(dst_class, exist_ok=True)\n",
    "\n",
    "    # Bilder aus Google Drive kopieren\n",
    "    for file in os.listdir(src_gd_class):\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            shutil.copy2(os.path.join(src_gd_class, file), os.path.join(dst_class, file))\n",
    "\n",
    "    # Falls diese Klasse auch im Zusatzordner vorhanden ist: Bilder ebenfalls kopieren\n",
    "    if os.path.isdir(src_additional_class):\n",
    "        for file in os.listdir(src_additional_class):\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                target_path = os.path.join(dst_class, file)\n",
    "                if not os.path.exists(target_path):  # nur kopieren, wenn noch nicht vorhanden\n",
    "                    shutil.copy2(os.path.join(src_additional_class, file), target_path)\n",
    "\n",
    "print(f\"âœ… Kombinierter Datensatz wurde unter '{combined_dir}' erstellt.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 110ms/step - accuracy: 0.8474 - loss: 0.4842 - val_accuracy: 0.9840 - val_loss: 0.0511\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - accuracy: 0.9734 - loss: 0.0923 - val_accuracy: 0.9875 - val_loss: 0.0371\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 110ms/step - accuracy: 0.9820 - loss: 0.0619 - val_accuracy: 0.9901 - val_loss: 0.0313\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 110ms/step - accuracy: 0.9841 - loss: 0.0526 - val_accuracy: 0.9894 - val_loss: 0.0330\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 111ms/step - accuracy: 0.9857 - loss: 0.0476 - val_accuracy: 0.9911 - val_loss: 0.0313\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 117ms/step - accuracy: 0.9877 - loss: 0.0395 - val_accuracy: 0.9909 - val_loss: 0.0302\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 119ms/step - accuracy: 0.9885 - loss: 0.0358 - val_accuracy: 0.9914 - val_loss: 0.0273\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 106ms/step - accuracy: 0.9888 - loss: 0.0326 - val_accuracy: 0.9922 - val_loss: 0.0274\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 107ms/step - accuracy: 0.9915 - loss: 0.0252 - val_accuracy: 0.9914 - val_loss: 0.0310\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 106ms/step - accuracy: 0.9910 - loss: 0.0265 - val_accuracy: 0.9919 - val_loss: 0.0284\n",
      "Test loss: 0.028386887162923813\n",
      "Test accuracy: 0.9919000267982483\n"
     ]
    }
   ],
   "source": [
    "# Train of mnsist cnn\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
    "from keras import backend as K\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, 28, 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)\n",
    "    input_shape = (1, 28, 28)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    input_shape = (28, 28, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=input_shape))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist_cnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4429 images belonging to 28 classes.\n",
      "Found 1097 images belonging to 28 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MeinNotebook/DocDig/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.1702 - loss: 3.8262 - val_accuracy: 0.3199 - val_loss: 2.5839\n",
      "Epoch 2/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186us/step - accuracy: 0.1875 - loss: 2.5217 - val_accuracy: 0.3333 - val_loss: 2.5219\n",
      "Epoch 3/50\n",
      "\u001b[1m  7/138\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.3719 - loss: 2.3350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.3600 - loss: 2.3733 - val_accuracy: 0.4338 - val_loss: 2.2741\n",
      "Epoch 4/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145us/step - accuracy: 0.4375 - loss: 2.3457 - val_accuracy: 0.5556 - val_loss: 2.0480\n",
      "Epoch 5/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.4727 - loss: 1.9744 - val_accuracy: 0.5009 - val_loss: 2.0910\n",
      "Epoch 6/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158us/step - accuracy: 0.6562 - loss: 1.8190 - val_accuracy: 0.5556 - val_loss: 1.3372\n",
      "Epoch 7/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5378 - loss: 1.8168 - val_accuracy: 0.5202 - val_loss: 2.0291\n",
      "Epoch 8/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65us/step - accuracy: 0.4688 - loss: 1.9045 - val_accuracy: 0.5556 - val_loss: 2.8931\n",
      "Epoch 9/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5780 - loss: 1.7058 - val_accuracy: 0.5579 - val_loss: 1.9451\n",
      "Epoch 10/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149us/step - accuracy: 0.5938 - loss: 1.5622 - val_accuracy: 0.7778 - val_loss: 1.0167\n",
      "Epoch 11/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6036 - loss: 1.6115 - val_accuracy: 0.5423 - val_loss: 1.9602\n",
      "Epoch 12/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63us/step - accuracy: 0.6562 - loss: 1.5690 - val_accuracy: 0.5556 - val_loss: 1.6455\n",
      "Epoch 13/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6402 - loss: 1.5638 - val_accuracy: 0.5781 - val_loss: 1.8791\n",
      "Epoch 14/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65us/step - accuracy: 0.7812 - loss: 1.4080 - val_accuracy: 0.5556 - val_loss: 1.4411\n",
      "Epoch 15/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6526 - loss: 1.4822 - val_accuracy: 0.6158 - val_loss: 1.7925\n",
      "Epoch 16/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77us/step - accuracy: 0.5938 - loss: 1.5662 - val_accuracy: 0.7778 - val_loss: 1.4477\n",
      "Epoch 17/50\n",
      "\u001b[1m  7/138\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6470 - loss: 1.5020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 12:46:15.669583: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6748 - loss: 1.4454 - val_accuracy: 0.5956 - val_loss: 1.8101\n",
      "Epoch 18/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64us/step - accuracy: 0.5312 - loss: 1.9003 - val_accuracy: 0.3333 - val_loss: 1.8974\n",
      "Epoch 19/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6981 - loss: 1.3911 - val_accuracy: 0.6158 - val_loss: 1.7634\n",
      "Epoch 20/50\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65us/step - accuracy: 0.7500 - loss: 1.3273 - val_accuracy: 0.6667 - val_loss: 1.2287\n"
     ]
    }
   ],
   "source": [
    "#train of species cnn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import json\n",
    "\n",
    "# Pfad zu Ihrem Hauptordner\n",
    "base_dir = '/Users/MeinNotebook/DocDig/Scans_for_Dataset/CombinedDataset'\n",
    "\n",
    "# BildgrÃ¶ÃŸen und BatchgrÃ¶ÃŸe definieren\n",
    "img_height, img_width = 22, 150\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2)\n",
    "\n",
    "# Keine Datenanreicherung fÃ¼r Validierungsdaten\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n",
    "\n",
    "# CNN Modell erstellen\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(img_height, img_width, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.1),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.1),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "class_indices = train_generator.class_indices\n",
    "with open('/Users/MeinNotebook/DocDig/class_indices.json', 'w') as file:\n",
    "    json.dump(class_indices, file)\n",
    "    \n",
    "    \n",
    "    \n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks definieren\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "model_checkpoint = ModelCheckpoint('vogelarten_best_model.keras', save_best_only=True)\n",
    "\n",
    "# Modell trainieren\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=50,  # Anzahl der Epochen kann angepasst werden\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "ğŸ“Š Klassengenauigkeit:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "                 \"       0.00      0.00      0.00        20\n",
      "        Alpenmeise       0.00      0.00      0.00        21\n",
      "        Baumpieper       0.00      0.00      0.00        24\n",
      "      Birkenzeisig       0.04      0.05      0.05        42\n",
      "         Blaumeise       0.08      0.11      0.09       136\n",
      "      Braunkelchen       0.00      0.00      0.00        20\n",
      "        Distelfink       0.07      0.05      0.06        43\n",
      "       Erlenzeisig       0.07      0.05      0.06        86\n",
      "             Fitis       0.17      0.05      0.07        21\n",
      "  Gartenrotschwanz       0.00      0.00      0.00        20\n",
      "       GartenrÃ¶tel       0.00      0.00      0.00        30\n",
      "        GelbspÃ¶ter       0.12      0.15      0.14        20\n",
      "           Girlitz       0.09      0.11      0.10        46\n",
      "     GrauschnÃ¤pper       0.00      0.00      0.00        23\n",
      "    Hausrotschwanz       0.05      0.05      0.05        20\n",
      "         HausrÃ¶tel       0.00      0.00      0.00        24\n",
      "   Heckenbraunelle       0.06      0.11      0.08        38\n",
      "          HÃ¤nfling       0.06      0.10      0.08        61\n",
      "  KlappergrasmÃ¼cke       0.07      0.10      0.08        20\n",
      "        Rotkelchen       0.00      0.00      0.00        20\n",
      "       Tannenmeise       0.16      0.18      0.17       184\n",
      "   TrauerschnÃ¤pper       0.04      0.03      0.03        30\n",
      "WintergoldhÃ¤hnchen       0.00      0.00      0.00        25\n",
      "     ZaungrasmÃ¼cke       0.17      0.10      0.12        20\n",
      "          Zilpzalp       0.00      0.00      0.00        25\n",
      "        Zitroneler       0.06      0.05      0.05        20\n",
      "      Zitronenfink       0.00      0.00      0.00        20\n",
      "    Zitronenzeisig       0.02      0.03      0.02        38\n",
      "\n",
      "          accuracy                           0.08      1097\n",
      "         macro avg       0.05      0.05      0.04      1097\n",
      "      weighted avg       0.07      0.08      0.07      1097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Hole die wahren Labels und Vorhersagen aus dem Validation-Generator\n",
    "# Achtung: shuffle=False wichtig fÃ¼r korrekte Zuordnung!\n",
    "validation_generator.reset()\n",
    "y_true = validation_generator.classes\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "# Vorhersagen berechnen\n",
    "Y_pred = model.predict(validation_generator, steps=validation_generator.samples // validation_generator.batch_size + 1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "# Klassifikationsbericht anzeigen\n",
    "print(\"ğŸ“Š Klassengenauigkeit:\")\n",
    "report = classification_report(y_true, y_pred, target_names=class_labels, digits=2)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vogelarten_final_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
